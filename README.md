# py-spark-
  PySpark DataFrame Operations: Joins, GroupBy, Filters, and More
Creating DataFrames in PySpark
- ✅ Filtering data using conditions
- ✅ Applying `withColumn` and data transformations
- ✅ Handling null values
- ✅ Performing joins
  - Inner Join
  - Left Join
  - Right Join
  - Full Outer Join
  - Left Semi Join
  - Left Anti Join
  ✅ Grouping data with `groupBy()` and applying aggregations like `count()`, `sum()`, `avg()`.
  Main notebook containing all code examples
